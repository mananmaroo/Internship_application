{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-04T03:56:21.291894Z","iopub.execute_input":"2021-11-04T03:56:21.292267Z","iopub.status.idle":"2021-11-04T03:56:21.323981Z","shell.execute_reply.started":"2021-11-04T03:56:21.292166Z","shell.execute_reply":"2021-11-04T03:56:21.323328Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"****Used a lot of approaches \nas you can see the last one detects the best one****","metadata":{}},{"cell_type":"code","source":"pip install xgboost","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:56:21.325509Z","iopub.execute_input":"2021-11-04T03:56:21.325955Z","iopub.status.idle":"2021-11-04T03:56:51.265987Z","shell.execute_reply.started":"2021-11-04T03:56:21.325923Z","shell.execute_reply":"2021-11-04T03:56:51.264982Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade xgboost","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:56:51.268122Z","iopub.execute_input":"2021-11-04T03:56:51.268446Z","iopub.status.idle":"2021-11-04T03:59:27.414690Z","shell.execute_reply.started":"2021-11-04T03:56:51.268398Z","shell.execute_reply":"2021-11-04T03:59:27.413425Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:27.417819Z","iopub.execute_input":"2021-11-04T03:59:27.418167Z","iopub.status.idle":"2021-11-04T03:59:28.419752Z","shell.execute_reply.started":"2021-11-04T03:59:27.418127Z","shell.execute_reply":"2021-11-04T03:59:28.419080Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv('/kaggle/input/customer-personality-analysis/marketing_campaign.csv', sep='\\t')\ndataset.head(6)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:28.450635Z","iopub.execute_input":"2021-11-04T03:59:28.450954Z","iopub.status.idle":"2021-11-04T03:59:28.524882Z","shell.execute_reply.started":"2021-11-04T03:59:28.450910Z","shell.execute_reply":"2021-11-04T03:59:28.524081Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y=dataset.Recency\nX=dataset.Income\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\nX_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:03:00.908255Z","iopub.execute_input":"2021-11-04T04:03:00.908591Z","iopub.status.idle":"2021-11-04T04:03:00.918457Z","shell.execute_reply.started":"2021-11-04T04:03:00.908534Z","shell.execute_reply":"2021-11-04T04:03:00.917635Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"seed = 8\ntest_size = 0.45\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:03:03.357709Z","iopub.execute_input":"2021-11-04T04:03:03.358422Z","iopub.status.idle":"2021-11-04T04:03:03.364543Z","shell.execute_reply.started":"2021-11-04T04:03:03.358379Z","shell.execute_reply":"2021-11-04T04:03:03.363637Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\npredict(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:04:56.243683Z","iopub.execute_input":"2021-11-04T04:04:56.243984Z","iopub.status.idle":"2021-11-04T04:04:56.276354Z","shell.execute_reply.started":"2021-11-04T04:04:56.243952Z","shell.execute_reply":"2021-11-04T04:04:56.275251Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:28.688987Z","iopub.status.idle":"2021-11-04T03:59:28.689292Z","shell.execute_reply.started":"2021-11-04T03:59:28.689125Z","shell.execute_reply":"2021-11-04T03:59:28.689148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nshap_values = shap.TreeExplainer(model).shap_values(X_train)\nshap.summary_plot(shap_values, X_train, plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:28.691632Z","iopub.status.idle":"2021-11-04T03:59:28.691936Z","shell.execute_reply.started":"2021-11-04T03:59:28.691779Z","shell.execute_reply":"2021-11-04T03:59:28.691795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shap_plot(j):\n    explainerModel = shap.TreeExplainer(model)\n    shap_values_Model = explainerModel.shap_values(S)\n    p = shap.force_plot(explainerModel.expected_value, shap_values_Model[j], S.iloc[[j]])\n    return(p)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:07:59.832287Z","iopub.execute_input":"2021-11-04T04:07:59.833020Z","iopub.status.idle":"2021-11-04T04:07:59.839905Z","shell.execute_reply.started":"2021-11-04T04:07:59.832966Z","shell.execute_reply":"2021-11-04T04:07:59.838917Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"shap_v = pd.DataFrame(df_shap)\nfeature_list = df.columns\nshap_v.columns = feature_list\ndf_v = df.copy().reset_index().drop('index',axis=1)\n\n# Determine the correlation in order to plot with different colors\ncorr_list = list()\nfor i in feature_list:\n    b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n    corr_list.append(b)\ncorr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n# Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\ncorr_df.columns  = ['Variable','Corr']\ncorr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n\n# Plot it\nshap_abs = np.abs(shap_v)\nk=pd.DataFrame(shap_abs.mean()).reset_index()\nk.columns = ['Variable','SHAP_abs']\nk2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\nk2 = k2.sort_values(by='SHAP_abs',ascending = True)\ncolorlist = k2['Sign']\nax = k2.plot.barh(x='Variable',y='SHAP_abs',color = colorlist, figsize=(5,6),legend=False)\nax.set_xlabel(\"SHAP Value (Red = Positive Impact)\")\n\nABS_SHAP(shap_values,X_train) ","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:08:01.754558Z","iopub.execute_input":"2021-11-04T04:08:01.755040Z","iopub.status.idle":"2021-11-04T04:08:01.782535Z","shell.execute_reply.started":"2021-11-04T04:08:01.754991Z","shell.execute_reply":"2021-11-04T04:08:01.781280Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nnp.random.seed(0)\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('/kaggle/input/customer-personality-analysis/marketing_campaign.csv', sep='\\t')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\n# The target variable is 'quality'.\ndf=df.dropna()\nY = df['Income']\nX =  df[['Recency', 'NumStorePurchases', 'NumWebVisitsMonth', 'NumDealsPurchases','Kidhome', 'Teenhome']]\n\n# Split the data into train and test data:\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n# Build the model with the random forest regression algorithm:\nmodel = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\nmodel.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:13:29.587664Z","iopub.execute_input":"2021-11-04T04:13:29.588473Z","iopub.status.idle":"2021-11-04T04:13:29.656981Z","shell.execute_reply.started":"2021-11-04T04:13:29.588431Z","shell.execute_reply":"2021-11-04T04:13:29.656419Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import shap\nshap_values = shap.TreeExplainer(model).shap_values(X_train)\nshap.summary_plot(shap_values, X_train, plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:13:46.924108Z","iopub.execute_input":"2021-11-04T04:13:46.924917Z","iopub.status.idle":"2021-11-04T04:13:48.623946Z","shell.execute_reply.started":"2021-11-04T04:13:46.924865Z","shell.execute_reply":"2021-11-04T04:13:48.623246Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n# Get the predictions and put them with the test data.\nX_output = X_test.copy()\nX_output.loc[:,'predict'] = np.round(model.predict(X_output),2)\n\n# Randomly pick some observations\nrandom_picks = np.arange(1,330,50) # Every 50 rows\nS = X_output.iloc[random_picks]\nS","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:14:38.260807Z","iopub.execute_input":"2021-11-04T04:14:38.261146Z","iopub.status.idle":"2021-11-04T04:14:38.285921Z","shell.execute_reply.started":"2021-11-04T04:14:38.261112Z","shell.execute_reply":"2021-11-04T04:14:38.284814Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def ABS_SHAP(df_shap,df):\n    #import matplotlib as plt\n    # Make a copy of the input data\n    shap_v = pd.DataFrame(df_shap)\n    feature_list = df.columns\n    shap_v.columns = feature_list\n    df_v = df.copy().reset_index().drop('index',axis=1)\n    \n    # Determine the correlation in order to plot with different colors\n    corr_list = list()\n    for i in feature_list:\n        b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n        corr_list.append(b)\n    corr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n    # Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\n    corr_df.columns  = ['Variable','Corr']\n    corr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n    \n    # Plot it\n    shap_abs = np.abs(shap_v)\n    k=pd.DataFrame(shap_abs.mean()).reset_index()\n    k.columns = ['Variable','SHAP_abs']\n    k2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n    k2 = k2.sort_values(by='SHAP_abs',ascending = True)\n    colorlist = k2['Sign']\n    ax = k2.plot.barh(x='Variable',y='SHAP_abs',color = colorlist, figsize=(5,6),legend=False)\n    ax.set_xlabel(\"SHAP Value (Red = Positive Impact)\")\n    \nABS_SHAP(shap_values,X_train) ","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:15:19.602452Z","iopub.execute_input":"2021-11-04T04:15:19.602768Z","iopub.status.idle":"2021-11-04T04:15:19.884436Z","shell.execute_reply.started":"2021-11-04T04:15:19.602732Z","shell.execute_reply":"2021-11-04T04:15:19.883547Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}