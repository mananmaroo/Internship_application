{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-04T03:56:21.291894Z","iopub.execute_input":"2021-11-04T03:56:21.292267Z","iopub.status.idle":"2021-11-04T03:56:21.323981Z","shell.execute_reply.started":"2021-11-04T03:56:21.292166Z","shell.execute_reply":"2021-11-04T03:56:21.323328Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"****Used a lot of approaches \nas you can see the last one detects the best one****","metadata":{}},{"cell_type":"code","source":"pip install xgboost","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:56:21.325509Z","iopub.execute_input":"2021-11-04T03:56:21.325955Z","iopub.status.idle":"2021-11-04T03:56:51.265987Z","shell.execute_reply.started":"2021-11-04T03:56:21.325923Z","shell.execute_reply":"2021-11-04T03:56:51.264982Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade xgboost","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:56:51.268122Z","iopub.execute_input":"2021-11-04T03:56:51.268446Z","iopub.status.idle":"2021-11-04T03:59:27.414690Z","shell.execute_reply.started":"2021-11-04T03:56:51.268398Z","shell.execute_reply":"2021-11-04T03:59:27.413425Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:27.417819Z","iopub.execute_input":"2021-11-04T03:59:27.418167Z","iopub.status.idle":"2021-11-04T03:59:28.419752Z","shell.execute_reply.started":"2021-11-04T03:59:27.418127Z","shell.execute_reply":"2021-11-04T03:59:28.419080Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv('/kaggle/input/customer-personality-analysis/marketing_campaign.csv', sep='\\t')\ndataset.head(6)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:28.450635Z","iopub.execute_input":"2021-11-04T03:59:28.450954Z","iopub.status.idle":"2021-11-04T03:59:28.524882Z","shell.execute_reply.started":"2021-11-04T03:59:28.450910Z","shell.execute_reply":"2021-11-04T03:59:28.524081Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"y=dataset.Recency\nX=dataset.Income\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\nX_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:03:00.908255Z","iopub.execute_input":"2021-11-04T04:03:00.908591Z","iopub.status.idle":"2021-11-04T04:03:00.918457Z","shell.execute_reply.started":"2021-11-04T04:03:00.908534Z","shell.execute_reply":"2021-11-04T04:03:00.917635Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"seed = 8\ntest_size = 0.45\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:03:03.357709Z","iopub.execute_input":"2021-11-04T04:03:03.358422Z","iopub.status.idle":"2021-11-04T04:03:03.364543Z","shell.execute_reply.started":"2021-11-04T04:03:03.358379Z","shell.execute_reply":"2021-11-04T04:03:03.363637Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","metadata":{"execution":{"iopub.status.busy":"2021-11-04T03:59:28.688987Z","iopub.status.idle":"2021-11-04T03:59:28.689292Z","shell.execute_reply.started":"2021-11-04T03:59:28.689125Z","shell.execute_reply":"2021-11-04T03:59:28.689148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nnp.random.seed(0)\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('/kaggle/input/customer-personality-analysis/marketing_campaign.csv', sep='\\t')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\n# The target variable is 'quality'.\ndf=df.dropna()\nY = df['Income']\nX =  df[['Recency', 'NumStorePurchases', 'NumWebVisitsMonth', 'NumDealsPurchases','MntWines', 'MntFruits','MntGoldProds','Response','NumWebPurchases','NumCatalogPurchases']]\n\n# Split the data into train and test data:\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n# Build the model with the random forest regression algorithm:\nmodel = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\nmodel.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:25:27.066571Z","iopub.execute_input":"2021-11-04T04:25:27.066866Z","iopub.status.idle":"2021-11-04T04:25:27.143255Z","shell.execute_reply.started":"2021-11-04T04:25:27.066830Z","shell.execute_reply":"2021-11-04T04:25:27.142479Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import shap\nshap_values = shap.TreeExplainer(model).shap_values(X_train)\nshap.summary_plot(shap_values, X_train, plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:25:30.262056Z","iopub.execute_input":"2021-11-04T04:25:30.262346Z","iopub.status.idle":"2021-11-04T04:25:30.681782Z","shell.execute_reply.started":"2021-11-04T04:25:30.262313Z","shell.execute_reply":"2021-11-04T04:25:30.680786Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n# Get the predictions and put them with the test data.\nX_output = X_test.copy()\nX_output.loc[:,'predict'] = np.round(model.predict(X_output),2)\n\n# Randomly pick some observations\nrandom_picks = np.arange(1,330,50) # Every 50 rows\nS = X_output.iloc[random_picks]\nS","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:25:38.399712Z","iopub.execute_input":"2021-11-04T04:25:38.399986Z","iopub.status.idle":"2021-11-04T04:25:38.421600Z","shell.execute_reply.started":"2021-11-04T04:25:38.399958Z","shell.execute_reply":"2021-11-04T04:25:38.420656Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def ABS_SHAP(df_shap,df):\n    #import matplotlib as plt\n    # Make a copy of the input data\n    shap_v = pd.DataFrame(df_shap)\n    feature_list = df.columns\n    shap_v.columns = feature_list\n    df_v = df.copy().reset_index().drop('index',axis=1)\n    \n    # Determine the correlation in order to plot with different colors\n    corr_list = list()\n    for i in feature_list:\n        b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n        corr_list.append(b)\n    corr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n    # Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\n    corr_df.columns  = ['Variable','Corr']\n    corr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n    \n    # Plot it\n    shap_abs = np.abs(shap_v)\n    k=pd.DataFrame(shap_abs.mean()).reset_index()\n    k.columns = ['Variable','SHAP_abs']\n    k2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n    k2 = k2.sort_values(by='SHAP_abs',ascending = True)\n    colorlist = k2['Sign']\n    ax = k2.plot.barh(x='Variable',y='SHAP_abs',color = colorlist, figsize=(5,6),legend=False)\n    ax.set_xlabel(\"SHAP Value (Red = Positive Impact)\")\n    \nABS_SHAP(shap_values,X_train) ","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:25:43.555286Z","iopub.execute_input":"2021-11-04T04:25:43.556118Z","iopub.status.idle":"2021-11-04T04:25:43.842516Z","shell.execute_reply.started":"2021-11-04T04:25:43.556069Z","shell.execute_reply":"2021-11-04T04:25:43.841622Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"shap.initjs()\n\n# Write in a function\ndef shap_plot(j):\n    explainerModel = shap.TreeExplainer(model)\n    shap_values_Model = explainerModel.shap_values(S)\n    p = shap.force_plot(explainerModel.expected_value, shap_values_Model[j], S.iloc[[j]])\n    return(p)\nshap_plot(0)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T04:32:13.488944Z","iopub.execute_input":"2021-11-04T04:32:13.489944Z","iopub.status.idle":"2021-11-04T04:32:13.518701Z","shell.execute_reply.started":"2021-11-04T04:32:13.489895Z","shell.execute_reply":"2021-11-04T04:32:13.517741Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}